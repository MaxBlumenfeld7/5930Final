{
  "best_metric": 0.22365118563175201,
  "best_model_checkpoint": "./results\\checkpoint-24000",
  "epoch": 9.6,
  "eval_steps": 2000,
  "global_step": 24000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 0.14469361305236816,
      "learning_rate": 0.000498,
      "loss": 1.3415,
      "step": 100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12462545186281204,
      "learning_rate": 0.000496,
      "loss": 0.3081,
      "step": 200
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.13755421340465546,
      "learning_rate": 0.000494,
      "loss": 0.2723,
      "step": 300
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.12591338157653809,
      "learning_rate": 0.000492,
      "loss": 0.2834,
      "step": 400
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.13759462535381317,
      "learning_rate": 0.00049,
      "loss": 0.2907,
      "step": 500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.13613665103912354,
      "learning_rate": 0.000488,
      "loss": 0.2854,
      "step": 600
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12962140142917633,
      "learning_rate": 0.000486,
      "loss": 0.2577,
      "step": 700
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.16412155330181122,
      "learning_rate": 0.000484,
      "loss": 0.2958,
      "step": 800
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.16023916006088257,
      "learning_rate": 0.000482,
      "loss": 0.2675,
      "step": 900
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11346624791622162,
      "learning_rate": 0.00048,
      "loss": 0.2663,
      "step": 1000
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.13346008956432343,
      "learning_rate": 0.00047799999999999996,
      "loss": 0.2607,
      "step": 1100
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.13212227821350098,
      "learning_rate": 0.00047599999999999997,
      "loss": 0.2781,
      "step": 1200
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14401455223560333,
      "learning_rate": 0.000474,
      "loss": 0.2697,
      "step": 1300
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.09840647131204605,
      "learning_rate": 0.000472,
      "loss": 0.2794,
      "step": 1400
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11762706190347672,
      "learning_rate": 0.00047,
      "loss": 0.269,
      "step": 1500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11360827833414078,
      "learning_rate": 0.00046800000000000005,
      "loss": 0.2753,
      "step": 1600
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.15413062274456024,
      "learning_rate": 0.00046600000000000005,
      "loss": 0.2754,
      "step": 1700
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.10172335803508759,
      "learning_rate": 0.00046400000000000006,
      "loss": 0.288,
      "step": 1800
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.13311727344989777,
      "learning_rate": 0.000462,
      "loss": 0.28,
      "step": 1900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0968274399638176,
      "learning_rate": 0.00046,
      "loss": 0.2562,
      "step": 2000
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.2575596272945404,
      "eval_runtime": 11.915,
      "eval_samples_per_second": 83.928,
      "eval_steps_per_second": 10.491,
      "step": 2000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.09401190280914307,
      "learning_rate": 0.000458,
      "loss": 0.2859,
      "step": 2100
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1365087479352951,
      "learning_rate": 0.000456,
      "loss": 0.2664,
      "step": 2200
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.10041838884353638,
      "learning_rate": 0.00045400000000000003,
      "loss": 0.2635,
      "step": 2300
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.13723599910736084,
      "learning_rate": 0.00045200000000000004,
      "loss": 0.2602,
      "step": 2400
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09916690737009048,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.2814,
      "step": 2500
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.10376251488924026,
      "learning_rate": 0.000448,
      "loss": 0.2528,
      "step": 2600
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.13343612849712372,
      "learning_rate": 0.000446,
      "loss": 0.2518,
      "step": 2700
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.10880777984857559,
      "learning_rate": 0.000444,
      "loss": 0.2674,
      "step": 2800
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.17273685336112976,
      "learning_rate": 0.000442,
      "loss": 0.2727,
      "step": 2900
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.08675751835107803,
      "learning_rate": 0.00044,
      "loss": 0.2626,
      "step": 3000
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.07538719475269318,
      "learning_rate": 0.000438,
      "loss": 0.2484,
      "step": 3100
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.10850366204977036,
      "learning_rate": 0.000436,
      "loss": 0.2677,
      "step": 3200
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.10468541830778122,
      "learning_rate": 0.00043400000000000003,
      "loss": 0.2716,
      "step": 3300
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.09729254990816116,
      "learning_rate": 0.000432,
      "loss": 0.2728,
      "step": 3400
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.11604098975658417,
      "learning_rate": 0.00043,
      "loss": 0.2598,
      "step": 3500
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.12100200355052948,
      "learning_rate": 0.000428,
      "loss": 0.2698,
      "step": 3600
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.15736685693264008,
      "learning_rate": 0.000426,
      "loss": 0.2601,
      "step": 3700
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.13542449474334717,
      "learning_rate": 0.000424,
      "loss": 0.2724,
      "step": 3800
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.08117757737636566,
      "learning_rate": 0.000422,
      "loss": 0.2844,
      "step": 3900
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.08366314321756363,
      "learning_rate": 0.00042,
      "loss": 0.2527,
      "step": 4000
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.2506283223628998,
      "eval_runtime": 11.9029,
      "eval_samples_per_second": 84.013,
      "eval_steps_per_second": 10.502,
      "step": 4000
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.1576196700334549,
      "learning_rate": 0.00041799999999999997,
      "loss": 0.2754,
      "step": 4100
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.08843815326690674,
      "learning_rate": 0.000416,
      "loss": 0.2588,
      "step": 4200
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.10859877616167068,
      "learning_rate": 0.000414,
      "loss": 0.2727,
      "step": 4300
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.12293968349695206,
      "learning_rate": 0.000412,
      "loss": 0.2621,
      "step": 4400
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.16898401081562042,
      "learning_rate": 0.00041,
      "loss": 0.2646,
      "step": 4500
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.1256466954946518,
      "learning_rate": 0.000408,
      "loss": 0.27,
      "step": 4600
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.09311822801828384,
      "learning_rate": 0.00040600000000000006,
      "loss": 0.2798,
      "step": 4700
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.12005351483821869,
      "learning_rate": 0.000404,
      "loss": 0.2572,
      "step": 4800
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.28704744577407837,
      "learning_rate": 0.000402,
      "loss": 0.2671,
      "step": 4900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.09150093048810959,
      "learning_rate": 0.0004,
      "loss": 0.265,
      "step": 5000
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.14676757156848907,
      "learning_rate": 0.000398,
      "loss": 0.2684,
      "step": 5100
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.14036999642848969,
      "learning_rate": 0.00039600000000000003,
      "loss": 0.2519,
      "step": 5200
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.09744295477867126,
      "learning_rate": 0.00039400000000000004,
      "loss": 0.2496,
      "step": 5300
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.10821956396102905,
      "learning_rate": 0.00039200000000000004,
      "loss": 0.2585,
      "step": 5400
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.12008672207593918,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.2568,
      "step": 5500
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.1307804435491562,
      "learning_rate": 0.000388,
      "loss": 0.2668,
      "step": 5600
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.14454469084739685,
      "learning_rate": 0.000386,
      "loss": 0.2556,
      "step": 5700
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.17274780571460724,
      "learning_rate": 0.000384,
      "loss": 0.2641,
      "step": 5800
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.11441650986671448,
      "learning_rate": 0.000382,
      "loss": 0.2684,
      "step": 5900
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.13834808766841888,
      "learning_rate": 0.00038,
      "loss": 0.2547,
      "step": 6000
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.24578459560871124,
      "eval_runtime": 11.891,
      "eval_samples_per_second": 84.097,
      "eval_steps_per_second": 10.512,
      "step": 6000
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.11816326528787613,
      "learning_rate": 0.000378,
      "loss": 0.2757,
      "step": 6100
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.13523408770561218,
      "learning_rate": 0.00037600000000000003,
      "loss": 0.2358,
      "step": 6200
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.1471514254808426,
      "learning_rate": 0.000374,
      "loss": 0.2559,
      "step": 6300
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.16584554314613342,
      "learning_rate": 0.000372,
      "loss": 0.2547,
      "step": 6400
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.14448687434196472,
      "learning_rate": 0.00037,
      "loss": 0.2619,
      "step": 6500
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.13689646124839783,
      "learning_rate": 0.000368,
      "loss": 0.2512,
      "step": 6600
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.13217468559741974,
      "learning_rate": 0.000366,
      "loss": 0.2658,
      "step": 6700
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.12785258889198303,
      "learning_rate": 0.000364,
      "loss": 0.2597,
      "step": 6800
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.11404814571142197,
      "learning_rate": 0.000362,
      "loss": 0.261,
      "step": 6900
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.14933638274669647,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.2552,
      "step": 7000
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.13640643656253815,
      "learning_rate": 0.000358,
      "loss": 0.2694,
      "step": 7100
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.155978262424469,
      "learning_rate": 0.000356,
      "loss": 0.2574,
      "step": 7200
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.1513891965150833,
      "learning_rate": 0.000354,
      "loss": 0.2562,
      "step": 7300
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.10718756914138794,
      "learning_rate": 0.000352,
      "loss": 0.2664,
      "step": 7400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.13504959642887115,
      "learning_rate": 0.00035,
      "loss": 0.2545,
      "step": 7500
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.12322588264942169,
      "learning_rate": 0.000348,
      "loss": 0.2522,
      "step": 7600
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.15676802396774292,
      "learning_rate": 0.000346,
      "loss": 0.2526,
      "step": 7700
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.08548246324062347,
      "learning_rate": 0.00034399999999999996,
      "loss": 0.2522,
      "step": 7800
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.10010451078414917,
      "learning_rate": 0.000342,
      "loss": 0.2411,
      "step": 7900
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.09038758277893066,
      "learning_rate": 0.00034,
      "loss": 0.2575,
      "step": 8000
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.24124911427497864,
      "eval_runtime": 12.7341,
      "eval_samples_per_second": 78.53,
      "eval_steps_per_second": 9.816,
      "step": 8000
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.10264041274785995,
      "learning_rate": 0.00033800000000000003,
      "loss": 0.2572,
      "step": 8100
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.10624061524868011,
      "learning_rate": 0.00033600000000000004,
      "loss": 0.2597,
      "step": 8200
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.11543982475996017,
      "learning_rate": 0.00033400000000000004,
      "loss": 0.2349,
      "step": 8300
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.09206828474998474,
      "learning_rate": 0.00033200000000000005,
      "loss": 0.2476,
      "step": 8400
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.13006538152694702,
      "learning_rate": 0.00033,
      "loss": 0.2564,
      "step": 8500
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.1259143054485321,
      "learning_rate": 0.000328,
      "loss": 0.2435,
      "step": 8600
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.14562195539474487,
      "learning_rate": 0.000326,
      "loss": 0.2576,
      "step": 8700
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.1500462144613266,
      "learning_rate": 0.000324,
      "loss": 0.2687,
      "step": 8800
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.12704144418239594,
      "learning_rate": 0.000322,
      "loss": 0.2634,
      "step": 8900
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.15139420330524445,
      "learning_rate": 0.00032,
      "loss": 0.2596,
      "step": 9000
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.12828586995601654,
      "learning_rate": 0.00031800000000000003,
      "loss": 0.2418,
      "step": 9100
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.1162298396229744,
      "learning_rate": 0.000316,
      "loss": 0.2491,
      "step": 9200
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.13857892155647278,
      "learning_rate": 0.000314,
      "loss": 0.2485,
      "step": 9300
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.13242611289024353,
      "learning_rate": 0.000312,
      "loss": 0.2666,
      "step": 9400
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.11194045841693878,
      "learning_rate": 0.00031,
      "loss": 0.2482,
      "step": 9500
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.13068845868110657,
      "learning_rate": 0.000308,
      "loss": 0.2576,
      "step": 9600
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.14256861805915833,
      "learning_rate": 0.000306,
      "loss": 0.2479,
      "step": 9700
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.13125759363174438,
      "learning_rate": 0.000304,
      "loss": 0.257,
      "step": 9800
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.13414610922336578,
      "learning_rate": 0.000302,
      "loss": 0.2761,
      "step": 9900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.15720456838607788,
      "learning_rate": 0.0003,
      "loss": 0.2405,
      "step": 10000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.23756161332130432,
      "eval_runtime": 11.9173,
      "eval_samples_per_second": 83.912,
      "eval_steps_per_second": 10.489,
      "step": 10000
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.142657071352005,
      "learning_rate": 0.000298,
      "loss": 0.2464,
      "step": 10100
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.12289410084486008,
      "learning_rate": 0.000296,
      "loss": 0.2427,
      "step": 10200
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.15419510006904602,
      "learning_rate": 0.000294,
      "loss": 0.2375,
      "step": 10300
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.10871855914592743,
      "learning_rate": 0.000292,
      "loss": 0.2549,
      "step": 10400
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.15821997821331024,
      "learning_rate": 0.00029,
      "loss": 0.2554,
      "step": 10500
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.16091087460517883,
      "learning_rate": 0.000288,
      "loss": 0.2591,
      "step": 10600
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.19381000101566315,
      "learning_rate": 0.00028599999999999996,
      "loss": 0.2526,
      "step": 10700
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.18849891424179077,
      "learning_rate": 0.00028399999999999996,
      "loss": 0.2561,
      "step": 10800
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.10073820501565933,
      "learning_rate": 0.00028199999999999997,
      "loss": 0.2426,
      "step": 10900
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.20305973291397095,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.2631,
      "step": 11000
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.16225440800189972,
      "learning_rate": 0.00027800000000000004,
      "loss": 0.2494,
      "step": 11100
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.14550647139549255,
      "learning_rate": 0.00027600000000000004,
      "loss": 0.244,
      "step": 11200
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.17282670736312866,
      "learning_rate": 0.00027400000000000005,
      "loss": 0.2438,
      "step": 11300
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.12041207402944565,
      "learning_rate": 0.00027200000000000005,
      "loss": 0.2483,
      "step": 11400
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.1792166531085968,
      "learning_rate": 0.00027,
      "loss": 0.2444,
      "step": 11500
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.15911120176315308,
      "learning_rate": 0.000268,
      "loss": 0.2603,
      "step": 11600
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.14706546068191528,
      "learning_rate": 0.000266,
      "loss": 0.2533,
      "step": 11700
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.1686074137687683,
      "learning_rate": 0.000264,
      "loss": 0.2447,
      "step": 11800
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.11934149265289307,
      "learning_rate": 0.000262,
      "loss": 0.2523,
      "step": 11900
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.15627354383468628,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.2497,
      "step": 12000
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.2342473566532135,
      "eval_runtime": 11.9188,
      "eval_samples_per_second": 83.901,
      "eval_steps_per_second": 10.488,
      "step": 12000
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.16795358061790466,
      "learning_rate": 0.00025800000000000004,
      "loss": 0.2502,
      "step": 12100
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.13976575434207916,
      "learning_rate": 0.000256,
      "loss": 0.2577,
      "step": 12200
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.12079060077667236,
      "learning_rate": 0.000254,
      "loss": 0.2195,
      "step": 12300
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.14391347765922546,
      "learning_rate": 0.000252,
      "loss": 0.2324,
      "step": 12400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.1594959944486618,
      "learning_rate": 0.00025,
      "loss": 0.2588,
      "step": 12500
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.17180724442005157,
      "learning_rate": 0.000248,
      "loss": 0.2523,
      "step": 12600
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.13249191641807556,
      "learning_rate": 0.000246,
      "loss": 0.2508,
      "step": 12700
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.15301527082920074,
      "learning_rate": 0.000244,
      "loss": 0.2496,
      "step": 12800
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.12349250912666321,
      "learning_rate": 0.000242,
      "loss": 0.2349,
      "step": 12900
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.217119961977005,
      "learning_rate": 0.00024,
      "loss": 0.2522,
      "step": 13000
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.14139530062675476,
      "learning_rate": 0.00023799999999999998,
      "loss": 0.263,
      "step": 13100
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.1209568902850151,
      "learning_rate": 0.000236,
      "loss": 0.2365,
      "step": 13200
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.16740410029888153,
      "learning_rate": 0.00023400000000000002,
      "loss": 0.2355,
      "step": 13300
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.1390448808670044,
      "learning_rate": 0.00023200000000000003,
      "loss": 0.2383,
      "step": 13400
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.2314240038394928,
      "learning_rate": 0.00023,
      "loss": 0.2477,
      "step": 13500
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.13746045529842377,
      "learning_rate": 0.000228,
      "loss": 0.2368,
      "step": 13600
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.18186333775520325,
      "learning_rate": 0.00022600000000000002,
      "loss": 0.256,
      "step": 13700
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.16389597952365875,
      "learning_rate": 0.000224,
      "loss": 0.2256,
      "step": 13800
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 0.19785484671592712,
      "learning_rate": 0.000222,
      "loss": 0.251,
      "step": 13900
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.16709795594215393,
      "learning_rate": 0.00022,
      "loss": 0.2487,
      "step": 14000
    },
    {
      "epoch": 5.6,
      "eval_loss": 0.23157745599746704,
      "eval_runtime": 11.9089,
      "eval_samples_per_second": 83.971,
      "eval_steps_per_second": 10.496,
      "step": 14000
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.195377916097641,
      "learning_rate": 0.000218,
      "loss": 0.2464,
      "step": 14100
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.14292693138122559,
      "learning_rate": 0.000216,
      "loss": 0.2381,
      "step": 14200
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.20457227528095245,
      "learning_rate": 0.000214,
      "loss": 0.2337,
      "step": 14300
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.13788937032222748,
      "learning_rate": 0.000212,
      "loss": 0.235,
      "step": 14400
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.13527649641036987,
      "learning_rate": 0.00021,
      "loss": 0.2548,
      "step": 14500
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.17159534990787506,
      "learning_rate": 0.000208,
      "loss": 0.2434,
      "step": 14600
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.23352576792240143,
      "learning_rate": 0.000206,
      "loss": 0.2414,
      "step": 14700
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.14933748543262482,
      "learning_rate": 0.000204,
      "loss": 0.245,
      "step": 14800
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.2003670334815979,
      "learning_rate": 0.000202,
      "loss": 0.2435,
      "step": 14900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.13364483416080475,
      "learning_rate": 0.0002,
      "loss": 0.2567,
      "step": 15000
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.14463748037815094,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.2319,
      "step": 15100
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.1998894214630127,
      "learning_rate": 0.00019600000000000002,
      "loss": 0.2297,
      "step": 15200
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.16264848411083221,
      "learning_rate": 0.000194,
      "loss": 0.2475,
      "step": 15300
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.12403597682714462,
      "learning_rate": 0.000192,
      "loss": 0.2347,
      "step": 15400
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.1874779760837555,
      "learning_rate": 0.00019,
      "loss": 0.2253,
      "step": 15500
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.14812105894088745,
      "learning_rate": 0.00018800000000000002,
      "loss": 0.265,
      "step": 15600
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.17289447784423828,
      "learning_rate": 0.000186,
      "loss": 0.2435,
      "step": 15700
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.2260292023420334,
      "learning_rate": 0.000184,
      "loss": 0.2408,
      "step": 15800
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.14801368117332458,
      "learning_rate": 0.000182,
      "loss": 0.2385,
      "step": 15900
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.22132186591625214,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.2475,
      "step": 16000
    },
    {
      "epoch": 6.4,
      "eval_loss": 0.22907140851020813,
      "eval_runtime": 11.8948,
      "eval_samples_per_second": 84.071,
      "eval_steps_per_second": 10.509,
      "step": 16000
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.13092732429504395,
      "learning_rate": 0.000178,
      "loss": 0.23,
      "step": 16100
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.15007756650447845,
      "learning_rate": 0.000176,
      "loss": 0.2513,
      "step": 16200
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.16170787811279297,
      "learning_rate": 0.000174,
      "loss": 0.2255,
      "step": 16300
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.17298009991645813,
      "learning_rate": 0.00017199999999999998,
      "loss": 0.2416,
      "step": 16400
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.17872434854507446,
      "learning_rate": 0.00017,
      "loss": 0.2357,
      "step": 16500
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.17506183683872223,
      "learning_rate": 0.00016800000000000002,
      "loss": 0.2494,
      "step": 16600
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.18646016716957092,
      "learning_rate": 0.00016600000000000002,
      "loss": 0.2482,
      "step": 16700
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.1833641231060028,
      "learning_rate": 0.000164,
      "loss": 0.2522,
      "step": 16800
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.2255616933107376,
      "learning_rate": 0.000162,
      "loss": 0.2428,
      "step": 16900
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.2080107480287552,
      "learning_rate": 0.00016,
      "loss": 0.2465,
      "step": 17000
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.1919228583574295,
      "learning_rate": 0.000158,
      "loss": 0.2373,
      "step": 17100
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.13943248987197876,
      "learning_rate": 0.000156,
      "loss": 0.2343,
      "step": 17200
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.16703081130981445,
      "learning_rate": 0.000154,
      "loss": 0.241,
      "step": 17300
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.18613941967487335,
      "learning_rate": 0.000152,
      "loss": 0.2494,
      "step": 17400
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.11912137269973755,
      "learning_rate": 0.00015,
      "loss": 0.2397,
      "step": 17500
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.17043422162532806,
      "learning_rate": 0.000148,
      "loss": 0.218,
      "step": 17600
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.13277243077754974,
      "learning_rate": 0.000146,
      "loss": 0.2513,
      "step": 17700
    },
    {
      "epoch": 7.12,
      "grad_norm": 0.16952815651893616,
      "learning_rate": 0.000144,
      "loss": 0.2421,
      "step": 17800
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.1961527317762375,
      "learning_rate": 0.00014199999999999998,
      "loss": 0.236,
      "step": 17900
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.1899266242980957,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.2345,
      "step": 18000
    },
    {
      "epoch": 7.2,
      "eval_loss": 0.2272019237279892,
      "eval_runtime": 11.8828,
      "eval_samples_per_second": 84.155,
      "eval_steps_per_second": 10.519,
      "step": 18000
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.14892379939556122,
      "learning_rate": 0.00013800000000000002,
      "loss": 0.2442,
      "step": 18100
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.1336948424577713,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.2515,
      "step": 18200
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.23355358839035034,
      "learning_rate": 0.000134,
      "loss": 0.2233,
      "step": 18300
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.2131851464509964,
      "learning_rate": 0.000132,
      "loss": 0.2431,
      "step": 18400
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.1420382261276245,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.2426,
      "step": 18500
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.1215156689286232,
      "learning_rate": 0.000128,
      "loss": 0.2451,
      "step": 18600
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.14339645206928253,
      "learning_rate": 0.000126,
      "loss": 0.2265,
      "step": 18700
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.1808350682258606,
      "learning_rate": 0.000124,
      "loss": 0.2594,
      "step": 18800
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.1743525266647339,
      "learning_rate": 0.000122,
      "loss": 0.2304,
      "step": 18900
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.2551339566707611,
      "learning_rate": 0.00012,
      "loss": 0.2386,
      "step": 19000
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.20667506754398346,
      "learning_rate": 0.000118,
      "loss": 0.2449,
      "step": 19100
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.20768015086650848,
      "learning_rate": 0.00011600000000000001,
      "loss": 0.223,
      "step": 19200
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.12561549246311188,
      "learning_rate": 0.000114,
      "loss": 0.2327,
      "step": 19300
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.20265726745128632,
      "learning_rate": 0.000112,
      "loss": 0.2285,
      "step": 19400
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.1994476616382599,
      "learning_rate": 0.00011,
      "loss": 0.2343,
      "step": 19500
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.1509179174900055,
      "learning_rate": 0.000108,
      "loss": 0.2336,
      "step": 19600
    },
    {
      "epoch": 7.88,
      "grad_norm": 0.19021166861057281,
      "learning_rate": 0.000106,
      "loss": 0.2443,
      "step": 19700
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.18866460025310516,
      "learning_rate": 0.000104,
      "loss": 0.2381,
      "step": 19800
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.20503176748752594,
      "learning_rate": 0.000102,
      "loss": 0.2527,
      "step": 19900
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.17555010318756104,
      "learning_rate": 0.0001,
      "loss": 0.2374,
      "step": 20000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.2254587560892105,
      "eval_runtime": 11.9527,
      "eval_samples_per_second": 83.663,
      "eval_steps_per_second": 10.458,
      "step": 20000
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.1494578868150711,
      "learning_rate": 9.800000000000001e-05,
      "loss": 0.2198,
      "step": 20100
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.12842132151126862,
      "learning_rate": 9.6e-05,
      "loss": 0.2467,
      "step": 20200
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.18613772094249725,
      "learning_rate": 9.400000000000001e-05,
      "loss": 0.2271,
      "step": 20300
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.17336255311965942,
      "learning_rate": 9.2e-05,
      "loss": 0.2494,
      "step": 20400
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.16373199224472046,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.2228,
      "step": 20500
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.15265978872776031,
      "learning_rate": 8.8e-05,
      "loss": 0.2296,
      "step": 20600
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.13452988862991333,
      "learning_rate": 8.599999999999999e-05,
      "loss": 0.231,
      "step": 20700
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.24381165206432343,
      "learning_rate": 8.400000000000001e-05,
      "loss": 0.2326,
      "step": 20800
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.16389210522174835,
      "learning_rate": 8.2e-05,
      "loss": 0.2229,
      "step": 20900
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.13832597434520721,
      "learning_rate": 8e-05,
      "loss": 0.2369,
      "step": 21000
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.17855559289455414,
      "learning_rate": 7.8e-05,
      "loss": 0.2408,
      "step": 21100
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.19877494871616364,
      "learning_rate": 7.6e-05,
      "loss": 0.2446,
      "step": 21200
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.17295216023921967,
      "learning_rate": 7.4e-05,
      "loss": 0.2199,
      "step": 21300
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.2185422033071518,
      "learning_rate": 7.2e-05,
      "loss": 0.2385,
      "step": 21400
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.25178927183151245,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.2566,
      "step": 21500
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.15219329297542572,
      "learning_rate": 6.800000000000001e-05,
      "loss": 0.2541,
      "step": 21600
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.14658354222774506,
      "learning_rate": 6.6e-05,
      "loss": 0.2523,
      "step": 21700
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.19576957821846008,
      "learning_rate": 6.4e-05,
      "loss": 0.2335,
      "step": 21800
    },
    {
      "epoch": 8.76,
      "grad_norm": 0.14529091119766235,
      "learning_rate": 6.2e-05,
      "loss": 0.2202,
      "step": 21900
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.14238351583480835,
      "learning_rate": 6e-05,
      "loss": 0.2267,
      "step": 22000
    },
    {
      "epoch": 8.8,
      "eval_loss": 0.2244054526090622,
      "eval_runtime": 11.9542,
      "eval_samples_per_second": 83.653,
      "eval_steps_per_second": 10.457,
      "step": 22000
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.14438217878341675,
      "learning_rate": 5.800000000000001e-05,
      "loss": 0.2497,
      "step": 22100
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.1679127812385559,
      "learning_rate": 5.6e-05,
      "loss": 0.2314,
      "step": 22200
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.15336230397224426,
      "learning_rate": 5.4e-05,
      "loss": 0.2275,
      "step": 22300
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.11763247847557068,
      "learning_rate": 5.2e-05,
      "loss": 0.2286,
      "step": 22400
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.18057139217853546,
      "learning_rate": 5e-05,
      "loss": 0.2502,
      "step": 22500
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.17036515474319458,
      "learning_rate": 4.8e-05,
      "loss": 0.2481,
      "step": 22600
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.15749146044254303,
      "learning_rate": 4.6e-05,
      "loss": 0.223,
      "step": 22700
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.12153053283691406,
      "learning_rate": 4.4e-05,
      "loss": 0.2354,
      "step": 22800
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.1984056681394577,
      "learning_rate": 4.2000000000000004e-05,
      "loss": 0.232,
      "step": 22900
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.2532311677932739,
      "learning_rate": 4e-05,
      "loss": 0.235,
      "step": 23000
    },
    {
      "epoch": 9.24,
      "grad_norm": 0.1909244954586029,
      "learning_rate": 3.8e-05,
      "loss": 0.2278,
      "step": 23100
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.2482985258102417,
      "learning_rate": 3.6e-05,
      "loss": 0.2443,
      "step": 23200
    },
    {
      "epoch": 9.32,
      "grad_norm": 0.1613961160182953,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.2261,
      "step": 23300
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.15878909826278687,
      "learning_rate": 3.2e-05,
      "loss": 0.2385,
      "step": 23400
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.18239812552928925,
      "learning_rate": 3e-05,
      "loss": 0.2332,
      "step": 23500
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.17465896904468536,
      "learning_rate": 2.8e-05,
      "loss": 0.2389,
      "step": 23600
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.17677749693393707,
      "learning_rate": 2.6e-05,
      "loss": 0.2232,
      "step": 23700
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.13468244671821594,
      "learning_rate": 2.4e-05,
      "loss": 0.2347,
      "step": 23800
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.17951129376888275,
      "learning_rate": 2.2e-05,
      "loss": 0.2277,
      "step": 23900
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.21820013225078583,
      "learning_rate": 2e-05,
      "loss": 0.2295,
      "step": 24000
    },
    {
      "epoch": 9.6,
      "eval_loss": 0.22365118563175201,
      "eval_runtime": 11.8935,
      "eval_samples_per_second": 84.079,
      "eval_steps_per_second": 10.51,
      "step": 24000
    }
  ],
  "logging_steps": 100,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.1456569065472e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
