{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98500c61-bd08-487c-96f2-64c9d70c602b",
   "metadata": {
    "id": "98500c61-bd08-487c-96f2-64c9d70c602b",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51be9fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "CUDA version: 11.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Max\\Documents\\Software\\5930\\finenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# CUDA settings\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Check CUDA availability and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    # Set default CUDA device\n",
    "    torch.cuda.set_device(0)\n",
    "    \n",
    "# Import other libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a064f14-44e7-4e92-8add-4405f5c2930d",
   "metadata": {
    "id": "8a064f14-44e7-4e92-8add-4405f5c2930d",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c14999",
   "metadata": {},
   "source": [
    "### load model and tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d182fd36-78a8-4c80-b327-05b00efb5492",
   "metadata": {
    "id": "d182fd36-78a8-4c80-b327-05b00efb5492",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer pad token: <|endoftext|>\n",
      "Tokenizer pad token ID: 50256\n",
      "Attempting to load model directly to device...\n",
      "Model loaded successfully\n",
      "\n",
      "Model device check:\n",
      "Model is on CUDA: True\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Set the pad_token to eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Print tokenizer info\n",
    "print(f\"Tokenizer pad token: {tokenizer.pad_token}\")\n",
    "print(f\"Tokenizer pad token ID: {tokenizer.pad_token_id}\")\n",
    "\n",
    "# Create model with explicit config\n",
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Try loading model with device placement in from_pretrained\n",
    "try:\n",
    "    print(\"Attempting to load model directly to device...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, \n",
    "        config=config,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        torch_dtype=torch.float32  # Explicitly set dtype\n",
    "    )\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model directly to device: {e}\")\n",
    "    print(\"Attempting alternate loading method...\")\n",
    "    # Try alternate loading method\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, config=config)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Moving model to CUDA...\")\n",
    "        # Try moving parts of the model gradually\n",
    "        for param in model.parameters():\n",
    "            param.data = param.data.to('cuda')\n",
    "    print(\"Model loading complete\")\n",
    "\n",
    "# Print model device info\n",
    "print(f\"\\nModel device check:\")\n",
    "print(f\"Model is on CUDA: {next(model.parameters()).is_cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dcbd66",
   "metadata": {},
   "source": [
    "### tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e323ad15-55f3-45ec-9f42-1be7455a4b94",
   "metadata": {
    "id": "e323ad15-55f3-45ec-9f42-1be7455a4b94",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define max length for the sequences\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "def format_alpaca_prompt(example):\n",
    "    \"\"\"Format the instruction and input into a prompt\"\"\"\n",
    "    if example[\"input\"]:\n",
    "        prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n\"\n",
    "    else:\n",
    "        prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n\"\n",
    "    return prompt\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize the texts and prepare them for training\"\"\"\n",
    "    # Tokenize with padding and truncation\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    labels = tokenized[\"input_ids\"].copy()\n",
    "    \n",
    "    # Find the start of the response for each example\n",
    "    for idx, text in enumerate(examples[\"text\"]):\n",
    "        response_start = text.find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
    "        # Get prompt tokens\n",
    "        prompt_tokens = len(tokenizer(text[:response_start], \n",
    "                                    truncation=True, \n",
    "                                    max_length=MAX_LENGTH)[\"input_ids\"])\n",
    "        \n",
    "        # Mask out prompt tokens in labels\n",
    "        labels[idx][:prompt_tokens] = [-100] * prompt_tokens\n",
    "        \n",
    "        # Ensure no out-of-bounds indices\n",
    "        if prompt_tokens > MAX_LENGTH:\n",
    "            labels[idx] = [-100] * MAX_LENGTH\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    input_ids = torch.tensor(tokenized[\"input_ids\"], dtype=torch.long)\n",
    "    attention_mask = torch.tensor(tokenized[\"attention_mask\"], dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Qnq6iT_cPyEs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "7f158e5a561048e3b6f590594444c158",
      "f59064cfad2947269049f743394173b1",
      "cff7af7a98dc46c68de733e2790cd9ef",
      "b99a828cd586471e9410e7879f46db81",
      "2aef35d22fb949969639fa94064a4457",
      "62d09efd889d4a8f88ad4b79ba0a361a",
      "46ef3ea2ec0845659b235ddc4c703053",
      "667a2a35cd5b42caa8b17a9d8adadf79",
      "09bda7a799e14df6a0a13abe210e7a69",
      "6f9da49a42f449cf971d8ba60d2ef9a8",
      "11235fb8a02241b1a8893d528f23bda6",
      "d8d2cf0e4f2e493fb72050f21af26b95",
      "19fd950f8a4a4d9caf2c70c926d574fa",
      "f2bb9a78b1d2425bb60ed4d40d4c6a4a",
      "95c413c637784ef29955840ce1406f37",
      "a0067481b71f4dec948e7c4d50faed9b",
      "476ac76184b14bacbb1c6f8afebb44ee",
      "893827e6c2d441b7acece76f5fdaa45e",
      "a345326dcec1442eb416fa74020684ca",
      "deaa7e1969b24b45b2700c2aecdc1c4a",
      "cac2e71a998e47e0a173f5406ae5efb6",
      "9cc805d627e946f895de513ff5e35313"
     ]
    },
    "id": "Qnq6iT_cPyEs",
    "outputId": "64ce133f-0a6f-469e-ed7c-bf336e3b28d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 46584/46584 [00:17<00:00, 2657.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing evaluation dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5176/5176 [00:01<00:00, 2645.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying data format:\n",
      "input_ids: shape=torch.Size([512]), dtype=torch.int64\n",
      "attention_mask: shape=torch.Size([512]), dtype=torch.int64\n",
      "labels: shape=torch.Size([512]), dtype=torch.int64\n",
      "\n",
      "Validating training dataset:\n",
      "Found 0 invalid samples\n",
      "\n",
      "Validating evaluation dataset:\n",
      "Found 0 invalid samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_alpaca_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def prepare_dataset(data):\n",
    "    \"\"\"Convert the JSON data into a format suitable for the model\"\"\"\n",
    "    formatted_data = []\n",
    "    for item in data:\n",
    "        prompt = format_alpaca_prompt(item)\n",
    "        formatted_data.append({\n",
    "            \"text\": prompt + item[\"output\"]  # Combine prompt and output\n",
    "        })\n",
    "    return Dataset.from_list(formatted_data)\n",
    "\n",
    "# Load and prepare the data\n",
    "alpaca_data = load_alpaca_data('alpaca_data_cleaned.json')\n",
    "train_size = int(0.9 * len(alpaca_data))\n",
    "train_data = alpaca_data[:train_size]\n",
    "eval_data = alpaca_data[train_size:]\n",
    "\n",
    "# Convert to Dataset format\n",
    "train_dataset = prepare_dataset(train_data)\n",
    "eval_dataset = prepare_dataset(eval_data)\n",
    "\n",
    "# Tokenize the datasets with smaller batch size and add error handling\n",
    "def safe_map_tokenization(dataset, batch_size=4):\n",
    "    try:\n",
    "        return dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            batch_size=batch_size,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during tokenization: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"Tokenizing training dataset...\")\n",
    "tokenized_train = safe_map_tokenization(train_dataset)\n",
    "print(\"Tokenizing evaluation dataset...\")\n",
    "tokenized_eval = safe_map_tokenization(eval_dataset)\n",
    "\n",
    "# Set the tensor format\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_eval.set_format(\"torch\")\n",
    "\n",
    "# Verify data format\n",
    "print(\"\\nVerifying data format:\")\n",
    "sample = tokenized_train[0]\n",
    "for key, value in sample.items():\n",
    "    print(f\"{key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "\n",
    "# Add validation check\n",
    "def validate_dataset(dataset, name):\n",
    "    print(f\"\\nValidating {name}:\")\n",
    "    invalid_samples = 0\n",
    "    for i, sample in enumerate(dataset):\n",
    "        if not all(isinstance(v, torch.Tensor) for v in sample.values()):\n",
    "            print(f\"Sample {i} has non-tensor values\")\n",
    "            invalid_samples += 1\n",
    "        if any(v.dtype not in [torch.long, torch.int64] for v in sample.values()):\n",
    "            print(f\"Sample {i} has incorrect dtype\")\n",
    "            invalid_samples += 1\n",
    "    print(f\"Found {invalid_samples} invalid samples\")\n",
    "    return invalid_samples == 0\n",
    "\n",
    "validate_dataset(tokenized_train, \"training dataset\")\n",
    "validate_dataset(tokenized_eval, \"evaluation dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc93b376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sizes - Train: 46584, Eval: 5176\n",
      "Scaled sizes - Train: 40000, Eval: 4000\n"
     ]
    }
   ],
   "source": [
    "# Scale datasets for testing\n",
    "def scale_dataset(dataset, max_samples=1000):\n",
    "    \"\"\"Scale down a dataset to a maximum number of samples\"\"\"\n",
    "    if len(dataset) > max_samples:\n",
    "        scaled_indices = list(range(max_samples))\n",
    "        return dataset.select(scaled_indices)\n",
    "    return dataset\n",
    "\n",
    "# Set your desired size\n",
    "MAX_SAMPLES = 40000  # Adjust this number as needed\n",
    "\n",
    "# Scale both datasets\n",
    "print(f\"Original sizes - Train: {len(tokenized_train)}, Eval: {len(tokenized_eval)}\")\n",
    "\n",
    "tokenized_train = scale_dataset(tokenized_train, MAX_SAMPLES)\n",
    "tokenized_eval = scale_dataset(tokenized_eval, max(50, int(MAX_SAMPLES * 0.1)))  # Keep eval set ~10% of train\n",
    "\n",
    "print(f\"Scaled sizes - Train: {len(tokenized_train)}, Eval: {len(tokenized_eval)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bQwXGOaRP1Ks",
   "metadata": {
    "id": "bQwXGOaRP1Ks"
   },
   "source": [
    "# Fine Tuning Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf808eb",
   "metadata": {},
   "source": [
    "### validate setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb90268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 50257\n",
      "Model vocab size: 50257\n",
      "input_ids - Min: -100, Max: 50256, Shape: torch.Size([512])\n",
      "attention_mask - Min: 0, Max: 1, Shape: torch.Size([512])\n",
      "labels - Min: -100, Max: 50256, Shape: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Check vocab sizes and data ranges\n",
    "print(f\"Tokenizer vocab size: {len(tokenizer)}\")\n",
    "print(f\"Model vocab size: {model.config.vocab_size}\")\n",
    "\n",
    "# Function to check tensor values\n",
    "def check_tensor_values(tensor, name):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        print(f\"{name} - Min: {tensor.min().item()}, Max: {tensor.max().item()}, Shape: {tensor.shape}\")\n",
    "\n",
    "# Check a sample from the dataset\n",
    "sample = tokenized_train[0]\n",
    "for key, value in sample.items():\n",
    "    check_tensor_values(value, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbe772",
   "metadata": {},
   "source": [
    "### custom collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74c0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Union, List, Dict, Any\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CustomDataCollatorForLanguageModeling:\n",
    "    tokenizer: AutoTokenizer\n",
    "    mlm: bool = False\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        # Extract the relevant fields\n",
    "        input_ids = [example[\"input_ids\"] for example in examples]\n",
    "        attention_mask = [example[\"attention_mask\"] for example in examples]\n",
    "        labels = [example[\"labels\"] for example in examples]\n",
    "\n",
    "        # Convert to tensors if they aren't already\n",
    "        if not isinstance(input_ids[0], torch.Tensor):\n",
    "            input_ids = [torch.tensor(ids, dtype=torch.long) for ids in input_ids]\n",
    "        if not isinstance(attention_mask[0], torch.Tensor):\n",
    "            attention_mask = [torch.tensor(mask, dtype=torch.long) for mask in attention_mask]\n",
    "        if not isinstance(labels[0], torch.Tensor):\n",
    "            labels = [torch.tensor(lab, dtype=torch.long) for lab in labels]\n",
    "\n",
    "        # Pad sequences\n",
    "        max_length = max(ids.size(0) for ids in input_ids)\n",
    "        \n",
    "        def pad_sequence(sequences, pad_value):\n",
    "            result = torch.full((len(sequences), max_length), pad_value, dtype=torch.long)\n",
    "            for i, seq in enumerate(sequences):\n",
    "                length = seq.size(0)\n",
    "                result[i, :length] = seq\n",
    "            return result\n",
    "\n",
    "        # Pad and create batch\n",
    "        input_ids_padded = pad_sequence(input_ids, self.tokenizer.pad_token_id)\n",
    "        attention_mask_padded = pad_sequence(attention_mask, 0)\n",
    "        labels_padded = pad_sequence(labels, -100)\n",
    "\n",
    "        # Ensure values are within vocabulary bounds\n",
    "        vocab_size = len(self.tokenizer)\n",
    "        input_ids_padded = torch.clamp(input_ids_padded, min=0, max=vocab_size-1)\n",
    "        labels_padded = torch.where(\n",
    "            (labels_padded >= 0) & (labels_padded < vocab_size),\n",
    "            labels_padded,\n",
    "            torch.tensor(-100, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids_padded,\n",
    "            \"attention_mask\": attention_mask_padded,\n",
    "            \"labels\": labels_padded\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723bbb20",
   "metadata": {},
   "source": [
    "### Training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d35308-23a8-4628-a218-81f73558f29c",
   "metadata": {
    "id": "45d35308-23a8-4628-a218-81f73558f29c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test batch shapes:\n",
      "input_ids: torch.Size([2, 512]), dtype: torch.int64, range: [0, 50256]\n",
      "attention_mask: torch.Size([2, 512]), dtype: torch.int64, range: [0, 1]\n",
      "labels: torch.Size([2, 512]), dtype: torch.int64, range: [-100, 50256]\n"
     ]
    }
   ],
   "source": [
    "# Training arguments with safe defaults\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    max_grad_norm=0.5,\n",
    "    gradient_accumulation_steps=16,\n",
    "    fp16=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "    prediction_loss_only=True,\n",
    "    seed=42,\n",
    "    full_determinism=False,\n",
    ")\n",
    "\n",
    "# Create custom collator\n",
    "data_collator = CustomDataCollatorForLanguageModeling(tokenizer=tokenizer)\n",
    "\n",
    "# Initialize trainer with custom collator\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Test the collator with a small batch\n",
    "test_batch = data_collator([tokenized_train[i] for i in range(2)])\n",
    "print(\"\\nTest batch shapes:\")\n",
    "for k, v in test_batch.items():\n",
    "    print(f\"{k}: {v.shape}, dtype: {v.dtype}, range: [{v.min()}, {v.max()}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RcQFXYQuN_Cl",
   "metadata": {
    "id": "RcQFXYQuN_Cl"
   },
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e060a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 100/7500 [00:54<1:07:24,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3474, 'grad_norm': 19.765625, 'learning_rate': 1e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 200/7500 [01:49<1:06:38,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8815, 'grad_norm': 17.582889556884766, 'learning_rate': 9.864864864864865e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 300/7500 [02:44<1:05:57,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.799, 'grad_norm': 13.08103084564209, 'learning_rate': 9.729729729729732e-06, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 400/7500 [03:39<1:04:23,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.814, 'grad_norm': 16.895729064941406, 'learning_rate': 9.594594594594594e-06, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 500/7500 [04:33<1:03:30,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7882, 'grad_norm': 15.232738494873047, 'learning_rate': 9.45945945945946e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 600/7500 [05:29<1:02:55,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8054, 'grad_norm': 14.510175704956055, 'learning_rate': 9.324324324324325e-06, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 700/7500 [06:24<1:01:50,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8102, 'grad_norm': 14.472683906555176, 'learning_rate': 9.189189189189191e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 800/7500 [07:18<1:00:56,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8215, 'grad_norm': 19.76947784423828, 'learning_rate': 9.054054054054054e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 900/7500 [08:13<1:00:24,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8231, 'grad_norm': 14.972772598266602, 'learning_rate': 8.91891891891892e-06, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1000/7500 [09:08<59:32,  1.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7909, 'grad_norm': 10.043087005615234, 'learning_rate': 8.783783783783785e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1100/7500 [10:03<57:59,  1.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7734, 'grad_norm': 13.947961807250977, 'learning_rate': 8.64864864864865e-06, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1200/7500 [10:58<57:16,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.796, 'grad_norm': 16.60686492919922, 'learning_rate': 8.513513513513514e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1300/7500 [11:52<56:12,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7882, 'grad_norm': 15.195953369140625, 'learning_rate': 8.378378378378378e-06, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1400/7500 [12:47<55:23,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7819, 'grad_norm': 14.62504768371582, 'learning_rate': 8.243243243243245e-06, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1500/7500 [13:42<54:40,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.782, 'grad_norm': 17.986557006835938, 'learning_rate': 8.108108108108109e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1600/7500 [14:37<53:29,  1.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7814, 'grad_norm': 18.64618492126465, 'learning_rate': 7.972972972972974e-06, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1700/7500 [15:33<52:32,  1.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7701, 'grad_norm': 14.773008346557617, 'learning_rate': 7.837837837837838e-06, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1800/7500 [16:27<51:42,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7671, 'grad_norm': 15.92533016204834, 'learning_rate': 7.702702702702704e-06, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1900/7500 [17:22<50:46,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7983, 'grad_norm': 16.766387939453125, 'learning_rate': 7.567567567567569e-06, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2000/7500 [18:16<50:05,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7934, 'grad_norm': 19.247142791748047, 'learning_rate': 7.4324324324324324e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2100/7500 [19:12<49:09,  1.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7908, 'grad_norm': 13.56124210357666, 'learning_rate': 7.297297297297298e-06, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2200/7500 [20:06<48:41,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7637, 'grad_norm': 16.501035690307617, 'learning_rate': 7.162162162162163e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2300/7500 [21:01<47:23,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7675, 'grad_norm': 15.458815574645996, 'learning_rate': 7.027027027027028e-06, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2400/7500 [21:57<46:52,  1.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7966, 'grad_norm': 13.347047805786133, 'learning_rate': 6.891891891891892e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2500/7500 [22:51<45:23,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7871, 'grad_norm': 15.287588119506836, 'learning_rate': 6.7567567567567575e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 33%|███▎      | 2500/7500 [23:21<45:23,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7420307397842407, 'eval_runtime': 29.0715, 'eval_samples_per_second': 137.592, 'eval_steps_per_second': 34.398, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 2600/7500 [24:16<44:31,  1.83it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7804, 'grad_norm': 16.078922271728516, 'learning_rate': 6.621621621621622e-06, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2700/7500 [25:10<43:23,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7738, 'grad_norm': 15.662795066833496, 'learning_rate': 6.486486486486487e-06, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2800/7500 [26:05<44:16,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7763, 'grad_norm': 16.26728630065918, 'learning_rate': 6.351351351351351e-06, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 2900/7500 [27:01<42:16,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7786, 'grad_norm': 17.553720474243164, 'learning_rate': 6.2162162162162164e-06, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 3000/7500 [27:56<41:52,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7506, 'grad_norm': 16.709016799926758, 'learning_rate': 6.081081081081082e-06, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 3100/7500 [28:53<40:18,  1.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7676, 'grad_norm': 17.314279556274414, 'learning_rate': 5.945945945945947e-06, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3200/7500 [29:49<40:01,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7928, 'grad_norm': 14.609395980834961, 'learning_rate': 5.810810810810811e-06, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 3300/7500 [30:45<38:43,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7393, 'grad_norm': 16.277332305908203, 'learning_rate': 5.675675675675676e-06, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 3400/7500 [31:41<37:43,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7627, 'grad_norm': 15.818199157714844, 'learning_rate': 5.540540540540541e-06, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 3500/7500 [32:36<37:15,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7682, 'grad_norm': 16.223543167114258, 'learning_rate': 5.405405405405406e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 3600/7500 [33:32<35:40,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7869, 'grad_norm': 15.99527645111084, 'learning_rate': 5.2702702702702705e-06, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 3700/7500 [34:28<35:25,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7636, 'grad_norm': 13.232833862304688, 'learning_rate': 5.135135135135135e-06, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 3800/7500 [35:23<34:55,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7651, 'grad_norm': 16.112136840820312, 'learning_rate': 5e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3900/7500 [36:21<33:45,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7849, 'grad_norm': 15.292614936828613, 'learning_rate': 4.864864864864866e-06, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4000/7500 [37:18<32:53,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7695, 'grad_norm': 17.34326171875, 'learning_rate': 4.72972972972973e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 4100/7500 [38:15<32:13,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7533, 'grad_norm': 17.508766174316406, 'learning_rate': 4.594594594594596e-06, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 4200/7500 [39:12<31:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7795, 'grad_norm': 17.97136878967285, 'learning_rate': 4.45945945945946e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4300/7500 [40:09<30:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7618, 'grad_norm': 16.25119400024414, 'learning_rate': 4.324324324324325e-06, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 4400/7500 [41:06<29:42,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7271, 'grad_norm': 16.641748428344727, 'learning_rate': 4.189189189189189e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 4500/7500 [42:03<27:29,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7239, 'grad_norm': 15.436436653137207, 'learning_rate': 4.0540540540540545e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 4600/7500 [42:59<26:36,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7598, 'grad_norm': 13.645821571350098, 'learning_rate': 3.918918918918919e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 4700/7500 [43:54<25:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7711, 'grad_norm': 16.235597610473633, 'learning_rate': 3.7837837837837844e-06, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 4800/7500 [44:49<24:32,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7294, 'grad_norm': 16.433752059936523, 'learning_rate': 3.648648648648649e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 4900/7500 [45:43<23:41,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7572, 'grad_norm': 13.83145523071289, 'learning_rate': 3.513513513513514e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 5000/7500 [46:38<22:50,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.76, 'grad_norm': 16.386600494384766, 'learning_rate': 3.3783783783783788e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 5000/7500 [47:08<22:50,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7303917407989502, 'eval_runtime': 29.2547, 'eval_samples_per_second': 136.73, 'eval_steps_per_second': 34.183, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 5100/7500 [48:03<21:52,  1.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7366, 'grad_norm': 19.54833984375, 'learning_rate': 3.2432432432432437e-06, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 5200/7500 [48:58<20:58,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7827, 'grad_norm': 16.02777671813965, 'learning_rate': 3.1081081081081082e-06, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 5300/7500 [49:52<20:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7522, 'grad_norm': 12.973928451538086, 'learning_rate': 2.9729729729729736e-06, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 5400/7500 [50:47<19:05,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7145, 'grad_norm': 15.294984817504883, 'learning_rate': 2.837837837837838e-06, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 5500/7500 [51:43<18:11,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7528, 'grad_norm': 16.698314666748047, 'learning_rate': 2.702702702702703e-06, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 5600/7500 [52:38<17:13,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7429, 'grad_norm': 18.034725189208984, 'learning_rate': 2.5675675675675675e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 5700/7500 [53:33<16:17,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7245, 'grad_norm': 9.858894348144531, 'learning_rate': 2.432432432432433e-06, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 5800/7500 [54:28<15:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7528, 'grad_norm': 15.5429105758667, 'learning_rate': 2.297297297297298e-06, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 5900/7500 [55:22<14:30,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7635, 'grad_norm': 15.096558570861816, 'learning_rate': 2.1621621621621623e-06, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 6000/7500 [56:17<13:35,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7329, 'grad_norm': 13.952903747558594, 'learning_rate': 2.0270270270270273e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 6100/7500 [57:12<12:44,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7483, 'grad_norm': 17.364910125732422, 'learning_rate': 1.8918918918918922e-06, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 6200/7500 [58:07<11:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7562, 'grad_norm': 14.73144817352295, 'learning_rate': 1.756756756756757e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 6300/7500 [59:01<10:54,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.768, 'grad_norm': 14.492931365966797, 'learning_rate': 1.6216216216216219e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 6400/7500 [59:56<09:58,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7643, 'grad_norm': 17.433677673339844, 'learning_rate': 1.4864864864864868e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 6500/7500 [1:00:51<09:05,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7692, 'grad_norm': 17.034439086914062, 'learning_rate': 1.3513513513513515e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 6600/7500 [1:01:46<08:11,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.757, 'grad_norm': 18.697004318237305, 'learning_rate': 1.2162162162162164e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 6700/7500 [1:02:41<07:16,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7565, 'grad_norm': 16.491140365600586, 'learning_rate': 1.0810810810810812e-06, 'epoch': 2.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 6800/7500 [1:03:35<06:22,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7888, 'grad_norm': 15.6122407913208, 'learning_rate': 9.459459459459461e-07, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 6900/7500 [1:04:30<05:29,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7522, 'grad_norm': 16.12258529663086, 'learning_rate': 8.108108108108109e-07, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 7000/7500 [1:05:25<04:33,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7725, 'grad_norm': 15.24124526977539, 'learning_rate': 6.756756756756758e-07, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 7100/7500 [1:06:20<03:37,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7631, 'grad_norm': 18.25636100769043, 'learning_rate': 5.405405405405406e-07, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 7200/7500 [1:07:15<02:43,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7491, 'grad_norm': 19.60845375061035, 'learning_rate': 4.0540540540540546e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 7300/7500 [1:08:09<01:49,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7423, 'grad_norm': 16.948884963989258, 'learning_rate': 2.702702702702703e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 7400/7500 [1:09:04<00:54,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7416, 'grad_norm': 19.66415023803711, 'learning_rate': 1.3513513513513515e-07, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [1:09:59<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7457, 'grad_norm': 15.98219108581543, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 7500/7500 [1:10:29<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7273839712142944, 'eval_runtime': 29.2309, 'eval_samples_per_second': 136.842, 'eval_steps_per_second': 34.21, 'epoch': 3.0}\n",
      "{'train_runtime': 4229.342, 'train_samples_per_second': 28.373, 'train_steps_per_second': 1.773, 'train_loss': 0.8044352213541667, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear CUDA cache and start training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Training error: {e}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\nCUDA Memory Summary:\")\n",
    "        print(torch.cuda.memory_summary())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52544118",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6268221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and tokenizer...\n",
      "Model and tokenizer saved to ./fine_tuned_alpaca_gpt2\n",
      "\n",
      "Verifying save...\n",
      "✓ Successfully loaded saved model and tokenizer\n"
     ]
    }
   ],
   "source": [
    "# Save paths\n",
    "model_save_path = \"./fine_tuned_alpaca_gpt2\"\n",
    "\n",
    "# Save the model and tokenizer\n",
    "print(\"Saving model and tokenizer...\")\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model and tokenizer saved to {model_save_path}\")\n",
    "\n",
    "# Quick verification that the save worked\n",
    "print(\"\\nVerifying save...\")\n",
    "try:\n",
    "    # Try to load the model and tokenizer\n",
    "    test_model = AutoModelForCausalLM.from_pretrained(model_save_path)\n",
    "    test_tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
    "    print(\"✓ Successfully loaded saved model and tokenizer\")\n",
    "except Exception as e:\n",
    "    print(f\"Error verifying save: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "finenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09bda7a799e14df6a0a13abe210e7a69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "11235fb8a02241b1a8893d528f23bda6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19fd950f8a4a4d9caf2c70c926d574fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_476ac76184b14bacbb1c6f8afebb44ee",
      "placeholder": "​",
      "style": "IPY_MODEL_893827e6c2d441b7acece76f5fdaa45e",
      "value": "Map: 100%"
     }
    },
    "2aef35d22fb949969639fa94064a4457": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46ef3ea2ec0845659b235ddc4c703053": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "476ac76184b14bacbb1c6f8afebb44ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62d09efd889d4a8f88ad4b79ba0a361a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "667a2a35cd5b42caa8b17a9d8adadf79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f9da49a42f449cf971d8ba60d2ef9a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f158e5a561048e3b6f590594444c158": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f59064cfad2947269049f743394173b1",
       "IPY_MODEL_cff7af7a98dc46c68de733e2790cd9ef",
       "IPY_MODEL_b99a828cd586471e9410e7879f46db81"
      ],
      "layout": "IPY_MODEL_2aef35d22fb949969639fa94064a4457"
     }
    },
    "893827e6c2d441b7acece76f5fdaa45e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95c413c637784ef29955840ce1406f37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cac2e71a998e47e0a173f5406ae5efb6",
      "placeholder": "​",
      "style": "IPY_MODEL_9cc805d627e946f895de513ff5e35313",
      "value": " 188/188 [00:00&lt;00:00, 872.19 examples/s]"
     }
    },
    "9cc805d627e946f895de513ff5e35313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0067481b71f4dec948e7c4d50faed9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a345326dcec1442eb416fa74020684ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b99a828cd586471e9410e7879f46db81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f9da49a42f449cf971d8ba60d2ef9a8",
      "placeholder": "​",
      "style": "IPY_MODEL_11235fb8a02241b1a8893d528f23bda6",
      "value": " 1836/1836 [00:02&lt;00:00, 898.93 examples/s]"
     }
    },
    "cac2e71a998e47e0a173f5406ae5efb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff7af7a98dc46c68de733e2790cd9ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_667a2a35cd5b42caa8b17a9d8adadf79",
      "max": 1836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09bda7a799e14df6a0a13abe210e7a69",
      "value": 1836
     }
    },
    "d8d2cf0e4f2e493fb72050f21af26b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19fd950f8a4a4d9caf2c70c926d574fa",
       "IPY_MODEL_f2bb9a78b1d2425bb60ed4d40d4c6a4a",
       "IPY_MODEL_95c413c637784ef29955840ce1406f37"
      ],
      "layout": "IPY_MODEL_a0067481b71f4dec948e7c4d50faed9b"
     }
    },
    "deaa7e1969b24b45b2700c2aecdc1c4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2bb9a78b1d2425bb60ed4d40d4c6a4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a345326dcec1442eb416fa74020684ca",
      "max": 188,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_deaa7e1969b24b45b2700c2aecdc1c4a",
      "value": 188
     }
    },
    "f59064cfad2947269049f743394173b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62d09efd889d4a8f88ad4b79ba0a361a",
      "placeholder": "​",
      "style": "IPY_MODEL_46ef3ea2ec0845659b235ddc4c703053",
      "value": "Map: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
